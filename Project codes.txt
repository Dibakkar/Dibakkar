import cv2
from ultralytics import YOLO
import matplotlib.pyplot as plt

# Load the YOLOv8 pre-trained model
model = YOLO('yolov8n.pt')  # Use a lightweight model for efficiency

def count_and_label_vehicles(frame):
    """
    Detect and count vehicles in a video frame using YOLO, and add labels to the frame.
    Args:
        frame: Input video frame.
    Returns:
        tuple: Modified frame with labels, count of detected vehicles.
    """
    results = model(frame)
    vehicle_classes = {2: "Car", 3: "Motorcycle", 5: "Bus", 7: "Truck"}  # COCO class IDs with names
    count = 0

    for box in results[0].boxes:
        cls = int(box.cls)  # Class ID of the detected object
        if cls in vehicle_classes:
            count += 1
            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates
            label = vehicle_classes[cls]
            confidence = float(box.conf)  # Convert tensor to float

            # Draw bounding box and label on the frame
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box
            cv2.putText(
                frame, f"{label} {confidence:.2f}", (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2  # Blue text
            )
    return frame, count

# Open the video file
video_path = r'C:\Users\LENOVO\New folder (3)\WhatsApp Video 2024-11-30 at 12.03.33_2f1f77b9.mp4'
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Error: Unable to open video file.")
    exit()

total_vehicle_count = 0
frame_count = 0

# Create a figure for displaying with Matplotlib
plt.ion()  # Turn on interactive mode
fig, ax = plt.subplots()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Detect and label vehicles in the current frame
    labeled_frame, vehicle_count = count_and_label_vehicles(frame)
    total_vehicle_count += vehicle_count
    frame_count += 1

    # Convert from BGR to RGB for Matplotlib
    frame_rgb = cv2.cvtColor(labeled_frame, cv2.COLOR_BGR2RGB)

    # Clear the previous frame and show the new frame
    ax.clear()
    ax.imshow(frame_rgb)
    ax.set_title(f"Vehicle Detection - Frame {frame_count}")
    ax.set_xlabel(f"Detected Vehicles: {vehicle_count}")
    plt.pause(0.1)  # Pause to allow the image to refresh

# Turn off interactive mode
plt.ioff()
cap.release()

# Final message
print(f"Total vehicles detected across all frames: {total_vehicle_count}")
plt.show()  # Keeps the last frame visible after the loop ends